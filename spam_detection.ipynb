{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3e79de6-3491-41cf-a25f-a93f498966c6",
   "metadata": {},
   "source": [
    "<h1><b>Importing the necessary Libraries</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc958c1d-7cb9-4781-85b7-abcfdc024101",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import spacy\n",
    "import nltk\n",
    "import re,string,unicodedata\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords   \n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7304abb1-32bc-4b56-8169-9eabca5f2192",
   "metadata": {},
   "source": [
    "<h1><b>Dataset Exploration</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c313b6b8-bcaa-47fd-96d0-d9ecc3116203",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"spam.csv\",encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d5dcdb0-c752-4a99-bb59-b40771a37266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9a01ee7-3a84-4f7e-92af-0e8c15a071aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['v1', 'v2', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fbf3eb8-7f88-464a-938b-59aebe41c434",
   "metadata": {},
   "outputs": [],
   "source": [
    "plus_col = ['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd2f24c5-9205-461a-a560-98d7c21e89b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = data.drop(plus_col,axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1e9e249-326f-4ac9-8d34-a2dee9961ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = new_data.rename(columns = {'v1':'target', 'v2':'email'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "606b0065-515b-41b5-b39d-a70550e60ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5120741-e63e-4ad7-bfe9-6614384a5479",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = new_data.drop_duplicates(keep = 'first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b71c8795-f24b-48d2-b0c8-213dfb3010d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target    False\n",
       "email     False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b24eb70c-04c1-42e1-a6dc-291c2673dadc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                              email\n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5fba387-d9de-4dbe-bd7a-d4881dd9cbfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5169</td>\n",
       "      <td>5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4516</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       target                                              email\n",
       "count    5169                                               5169\n",
       "unique      2                                               5169\n",
       "top       ham  Go until jurong point, crazy.. Available only ...\n",
       "freq     4516                                                  1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49bddd0-f0ba-4f15-9072-5c0c651e3cdd",
   "metadata": {},
   "source": [
    "<h1><b>NLP Tools Application on the text Field</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2a769d-b62c-46e5-876a-9f812ae79819",
   "metadata": {},
   "source": [
    "<h3><b>Summary of The Steps Applied here</b></h3>\n",
    "<p>in this section i tried to prepare the text in the v2 field in a way that it would be in a much better shape while using it for creating the model</p>\n",
    "<p>the steps are very simple </p>\n",
    "<ul>\n",
    "<li>first removing all the html tags and special noisy characters from the text since they don't provide any useful informations for our model</li>\n",
    "<li>second stemming the text which means removing the prefixes and suffixes that are added to words (like 's' in the plural form and the 's' in verbs conjugated with \"he she and it\", this transformation is very useful and important since we're going to apply the vectorization on this text and by applying this step we will avoid replication of words like instead of having 'like' and 'likes' we will just have 'like' in the set of features </li>\n",
    "<li>third removing stopwords and and punctuations since the first one mentioned don't provide any useful informations and about the punctuation it is also recommended to remove them </li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06c51e27-e286-4014-9d45-96f33a53cd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the noisy text\n",
    "def noiseremoval_text(text):\n",
    "  soup = BeautifulSoup(text, \"html.parser\")\n",
    "  text = soup.get_text()\n",
    "  text = re.sub('\\[[^]]*\\]', '', text)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1dc2dde-4ba7-4907-9cff-5820d4edabe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yboyk\\AppData\\Local\\Temp\\ipykernel_4796\\763603513.py:3: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(text, \"html.parser\")\n"
     ]
    }
   ],
   "source": [
    "new_data['email']=new_data['email'].apply(noiseremoval_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d51dbd79-851e-41d3-88f5-47603361deba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                              email\n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "efc01aa1-0233-45d8-8229-ab2e362e2c20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go until jurong point, crazy.. avail onli in b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar... joke wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entri in 2 a wkli comp to win fa cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say so earli hor... u c alreadi then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah i don't think he goe to usf, he live aroun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                              email\n",
       "0    ham  go until jurong point, crazy.. avail onli in b...\n",
       "1    ham                        ok lar... joke wif u oni...\n",
       "2   spam  free entri in 2 a wkli comp to win fa cup fina...\n",
       "3    ham  u dun say so earli hor... u c alreadi then say...\n",
       "4    ham  nah i don't think he goe to usf, he live aroun..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stemming the text\n",
    "def stemmer(text):\n",
    "    ps=nltk.porter.PorterStemmer()\n",
    "    text= ' '.join([ps.stem(word) for word in text.split()])\n",
    "    return text\n",
    "    \n",
    "new_data['email']=new_data['email'].apply(stemmer)\n",
    "\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db5a5086-3b49-4a49-816a-86dbed2c065f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_wr=set(stopwords.words('english'))\n",
    "\n",
    "def remove_punc_stopword(text):\n",
    "\n",
    "    remove_punc = [word for word in text.lower() if word not in string.punctuation]\n",
    "    remove_punc = ''.join(remove_punc)\n",
    "    return [word for word in remove_punc.split() if word not in stop_wr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4ed0367-5b63-478b-b625-35283deaada4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[go, jurong, point, crazy, avail, onli, bugi, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[u, dun, say, earli, hor, u, c, alreadi, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[nah, dont, think, goe, usf, live, around, tho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                              email\n",
       "0    ham  [go, jurong, point, crazy, avail, onli, bugi, ...\n",
       "1    ham                       [ok, lar, joke, wif, u, oni]\n",
       "2   spam  [free, entri, 2, wkli, comp, win, fa, cup, fin...\n",
       "3    ham      [u, dun, say, earli, hor, u, c, alreadi, say]\n",
       "4    ham  [nah, dont, think, goe, usf, live, around, tho..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data = new_data.copy()\n",
    "cleaned_data['email'] = new_data['email'].apply(remove_punc_stopword)\n",
    "cleaned_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6627be93-3e34-4061-aaf3-bfb42e6c831c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    go jurong point crazy avail onli bugi n great ...\n",
      "1                                ok lar joke wif u oni\n",
      "2    free entri 2 wkli comp win fa cup final tkt 21...\n",
      "3                  u dun say earli hor u c alreadi say\n",
      "4            nah dont think goe usf live around though\n",
      "Name: original_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "cleaned_data['original_text'] = cleaned_data['email'].apply(lambda words: ' '.join(words))\n",
    "\n",
    "y = cleaned_data['target']\n",
    "x = cleaned_data['original_text']\n",
    "\n",
    "print(cleaned_data['original_text'][0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44ce6ac-88f0-44ba-9529-a961e11ccc07",
   "metadata": {},
   "source": [
    "<h1><b>Transforming the dataset into a Sparse Matrix</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1c3b02-b8d8-48aa-915d-b60673ac84c6",
   "metadata": {},
   "source": [
    "<p>here i transformed the text found in the email field into a bag of words which means i will create a matrix that for every new distinct word found in the field of email it will count the number of its occurences across all the records but for testing i kept only 200 words or 'features' that are most frequent using the max_features parameter with  the countvectorizer object</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "726f454e-d5b4-41a1-a4aa-88d2dab70830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the sparse matrix:  (5169, 200)\n"
     ]
    }
   ],
   "source": [
    "#Count vectorizer for bag of words\n",
    "\n",
    "cv = CountVectorizer(ngram_range=(1,3),max_features= 200)\n",
    "x_cv = cv.fit_transform(x)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_cv,y, test_size=0.2, random_state = 1)\n",
    "print(\"Shape of the sparse matrix: \", x_cv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd61dbe2-c9a0-4684-abc1-4272086d2577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alreadi</th>\n",
       "      <th>already</th>\n",
       "      <th>also</th>\n",
       "      <th>alway</th>\n",
       "      <th>ani</th>\n",
       "      <th>anyth</th>\n",
       "      <th>around</th>\n",
       "      <th>ask</th>\n",
       "      <th>award</th>\n",
       "      <th>babe</th>\n",
       "      <th>...</th>\n",
       "      <th>word</th>\n",
       "      <th>work</th>\n",
       "      <th>would</th>\n",
       "      <th>ya</th>\n",
       "      <th>ye</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yet</th>\n",
       "      <th>yup</th>\n",
       "      <th>ìï</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5164</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5165</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5166</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5168</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5169 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      alreadi  already  also  alway  ani  anyth  around  ask  award  babe  \\\n",
       "0           0        0     0      0    0      0       0    0      0     0   \n",
       "1           0        0     0      0    0      0       0    0      0     0   \n",
       "2           0        0     0      0    0      0       0    0      0     0   \n",
       "3           1        0     0      0    0      0       0    0      0     0   \n",
       "4           0        0     0      0    0      0       1    0      0     0   \n",
       "...       ...      ...   ...    ...  ...    ...     ...  ...    ...   ...   \n",
       "5164        0        0     0      0    0      0       0    0      0     0   \n",
       "5165        0        0     0      0    0      0       0    0      0     0   \n",
       "5166        0        0     0      0    0      0       0    0      0     0   \n",
       "5167        0        0     0      0    0      0       0    0      0     0   \n",
       "5168        0        0     0      0    0      0       0    0      0     0   \n",
       "\n",
       "      ...  word  work  would  ya  ye  yeah  year  yet  yup  ìï  \n",
       "0     ...     0     0      0   0   0     0     0    0    0   0  \n",
       "1     ...     0     0      0   0   0     0     0    0    0   0  \n",
       "2     ...     0     0      0   0   0     0     0    0    0   0  \n",
       "3     ...     0     0      0   0   0     0     0    0    0   0  \n",
       "4     ...     0     0      0   0   0     0     0    0    0   0  \n",
       "...   ...   ...   ...    ...  ..  ..   ...   ...  ...  ...  ..  \n",
       "5164  ...     0     0      0   0   0     0     0    0    0   0  \n",
       "5165  ...     0     0      0   0   0     0     0    0    0   0  \n",
       "5166  ...     0     0      0   0   0     0     0    0    0   0  \n",
       "5167  ...     0     0      0   0   0     0     0    0    0   0  \n",
       "5168  ...     0     0      0   0   0     0     0    0    0   0  \n",
       "\n",
       "[5169 rows x 200 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vectorized = pd.DataFrame(x_cv.toarray(), columns=cv.get_feature_names_out())\n",
    "df_vectorized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba40280-9fd8-4775-ae98-595f2898e993",
   "metadata": {},
   "source": [
    "<h1><b>Model Creation and Evaluation</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcb1f92-f052-406c-a9e3-0b2d87dc9324",
   "metadata": {},
   "source": [
    "<h5><b>here i created two different models that are largely used in the field of NLP which are Logistic Regression and Naive Bayes</b></h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f6585d1-325d-4ef2-88ac-1fe41c8026a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Multinomial Naive Bayes:\n",
      "[[881  18]\n",
      " [ 31 104]]\n",
      "Score: 95.26\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      0.98      0.97       899\n",
      "        spam       0.85      0.77      0.81       135\n",
      "\n",
      "    accuracy                           0.95      1034\n",
      "   macro avg       0.91      0.88      0.89      1034\n",
      "weighted avg       0.95      0.95      0.95      1034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "\n",
    "mnb.fit(x_train,y_train)\n",
    "predmnb = mnb.predict(x_test)\n",
    "\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,predmnb))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predmnb)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predmnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ad4c061-1510-4f1c-9caa-d34b488326d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Multinomial Naive Bayes:\n",
      "[[893   6]\n",
      " [ 37  98]]\n",
      "Score: 95.84\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      0.99      0.98       899\n",
      "        spam       0.94      0.73      0.82       135\n",
      "\n",
      "    accuracy                           0.96      1034\n",
      "   macro avg       0.95      0.86      0.90      1034\n",
      "weighted avg       0.96      0.96      0.96      1034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "predclf = clf.predict(x_test)\n",
    "\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,predclf))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predclf)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predclf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
